{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pycld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sweetviz\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import csv\n",
    "import emoji\n",
    "from typing import List\n",
    "from flair.data import Token\n",
    "import sys,os\n",
    "import tqdm\n",
    "import pycld2 as cld2\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./', './data')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'config.txt'\n",
    "configParser.read(configFilePath)\n",
    "csvpath = configParser.get('paths', 'csvpath')\n",
    "outpath = configParser.get('paths', 'outpath')\n",
    "outpath,csvpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.amharicSegmenter import AmharicSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(string): \n",
    "    text = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',string)\n",
    "    return \"\".join(text) # converting return value from list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eng(string): \n",
    "    text = re.findall('[a-zA-Z0-9]',string)\n",
    "    return \"\".join(text) # converting return value from list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data):\n",
    "    return data.replace(find_url(data),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_eng(data):\n",
    "    return ' '.join(re.sub(u\"[^ሀ-፼]\", \" \", data).split()).strip()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_English_letters(content):\n",
    "    for idx,cnt in enumerate(content):\n",
    "        content[idx] = re.sub(r'\\s*[A-Za-z]+\\b','', cnt)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(news):\n",
    "    news = emoji.demojize(news)\n",
    "    re.sub('(:\\S+)(@\\w+)','', news)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicated_values_data(data):\n",
    "    dup=[]\n",
    "    columns=data.columns\n",
    "    for i in data.columns:\n",
    "        dup.append(sum(data[i].duplicated()))\n",
    "    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_punct = []\n",
    "word_punct = []\n",
    "amseg = AmharicSegmenter(sent_punct,word_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read each CSV files and write it to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "remove = ['\\xa087','\\xa0', '|', '/','…','«','\"','“','”','»','-',\n",
    "          '$','%','^','&','*','›','’','‘','‹','<','>','`','´','~','=','+']\n",
    "# remove output file if it exists, then append each csv to a single file output\n",
    "outfile = outpath+\"all_sentences.txt\"\n",
    "os.remove(outfile) if os.path.exists(outfile) else None\n",
    "# all csv files, to controll progress par\n",
    "allnews = []\n",
    "for news in glob.glob(csvpath+\"/*.csv\"):\n",
    "    allnews.append(news)\n",
    "    \n",
    "# read each files and write to a file system \n",
    "with open (outfile,\"a\", encoding=\"utf-8\") as all_sentences:\n",
    "    for news in tqdm.tqdm(allnews,  position=0, leave=True):\n",
    "        data = pd.read_csv(news, names=[\"ID\",\"URL\",\"Date\",\"Media\",\"Content\"] ,encoding=\"utf-8\")\n",
    "        data = data[data.Content.duplicated()==False].reset_index()\n",
    "        #data.Content = data.Content.apply(lambda x: remove_url(x))\n",
    "        #data.Content = data.Content.apply(lambda x: remove_emoji(x))\n",
    "        data.Content = data.Content.apply(lambda x: remove_eng(x))\n",
    "        for token in remove:\n",
    "            data.Content = data.Content.apply(lambda x: x.replace(token,' '))  \n",
    "        for text in data.Content:\n",
    "            for s in amseg.tokenize_sentence(text):\n",
    "                isReliable, textBytesFound, details  = cld2.detect(s)\n",
    "                if details[0][1] =='am':\n",
    "                    all_sentences.write(s.replace('\\n','')+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
