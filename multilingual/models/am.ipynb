{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sweetviz\n",
    "import random\n",
    "import warnings\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import csv\n",
    "import emoji\n",
    "from typing import List\n",
    "from flair.data import Token\n",
    "import sys,os\n",
    "import tqdm\n",
    "import pycld2 as cld2\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'config.txt'\n",
    "configParser.read(configFilePath)\n",
    "csvpath = configParser.get('paths', 'csvpath')\n",
    "outpath = configParser.get('paths', 'outpath')\n",
    "outpath,csvpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10682f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.amharicSegmenter import AmharicSegmenter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b42f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(string): \n",
    "    text = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',string)\n",
    "    return \"\".join(text) # converting return value from list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096564f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data):\n",
    "    return data.replace(find_url(data),\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_eng(data):\n",
    "    return ' '.join(re.sub(u\"[^ሀ-፼]\", \" \", data).split()).strip()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(news):\n",
    "    news = emoji.demojize(news)\n",
    "    re.sub('(:\\S+)(@\\w+)','', news)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicated_values_data(data):\n",
    "    dup=[]\n",
    "    columns=data.columns\n",
    "    for i in data.columns:\n",
    "        dup.append(sum(data[i].duplicated()))\n",
    "    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_punct = []\n",
    "word_punct = []\n",
    "amseg = AmharicSegmenter(sent_punct,word_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73628e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.50s/it]\n"
     ]
    }
   ],
   "source": [
    "outfile = outpath+\"/am_all_sentences.txt\" #tig_all_sentences.txt for tigregna\n",
    "os.remove(outfile) if os.path.exists(outfile) else None\n",
    "\n",
    "allnews = []\n",
    "for news in glob.glob(csvpath+\"/*.csv\"):\n",
    "    allnews.append(news)\n",
    "    \n",
    "# read each files and write to a file system \n",
    "\n",
    "with open (outfile,\"a\", encoding=\"utf-8\") as all_sentences:\n",
    "    lines_seen = set() # holds lines already seen\n",
    "    for news in tqdm.tqdm(allnews,  position=0, leave=True):\n",
    "        data = pd.read_csv(news, names=[\"id\",\"url\",\"date\",\"title\",\"text\",\"html\"] ,encoding=\"utf-8\")\n",
    "        data = data[data.text.duplicated()==False].reset_index()\n",
    "        data.text = data.text.apply(lambda x: remove_url(x))\n",
    "        #data.text = data.text.apply(lambda x: remove_emoji(x))\n",
    "        #data.text = data.text.apply(lambda x: remove_eng(x))\n",
    "        #for token in remove:\n",
    "        #    data.text = data.text.apply(lambda x: x.replace(token,' '))  \n",
    "        for text in data.text:\n",
    "            for s in amseg.tokenize_sentence(text):\n",
    "                isReliable, textBytesFound, details  = cld2.detect(s)\n",
    "                if details[0][1] =='am' and s not in lines_seen: # am=amharic ti=tigrenya,                 \n",
    "                    all_sentences.write(' '.join(t.text for t in amseg.amharic_tokenizer(s))+'\\n')\n",
    "                    lines_seen.add(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6b08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c3f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Orommigna\n",
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85c6042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da55e7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Akkuma fakkii Lii’oonaardoo Daavinchii kana ilaallee dinqisiifannu jaarraa 16ffaa keessa Xaaliyaanitti yeroo fakkiin kun kaafamu foolii ture suufuu otoo dandeenyee hoo?',\n",
       " '22 Sadaasa 2020\\nViidiyoon kabaja “waadaa galuu” Imbaasii Ruwaandaa Landan keessatti yemmuu gaggeeffamuu agarsiisu ba’e, biyyaa Baha Afrikaa qeeqtootaan “Kooriyaa Kaabaa” haaraa jedhamte irratti himannaa abba irrummaa jiru guddiseera.',\n",
       " '19 Sadaasa 2020\\nJoy Baayiden waggoota 40 oliif nama siyaasa Ameerikaa keessatti haalaan beekamudha.',\n",
       " \"Bu'aa bahiin jireenya isaanii maal fakkaata?\",\n",
       " '7 Sadaasa 2020\\nBaqataan Itoophiyaa dargaggummaan Ameerikaatti godaanuun, dhiyeenyatti lammummaa biyyattii argate, kutaa biyyaa Mineesotaa teessoo mana maree Ostin injifachuun seenaa galmeesse.',\n",
       " '11 Sadaasa 2020\\nWaldhabdeen paartii naannoo Tigiraay bulchaa jiruu (TPLF)fi mootummaa giddu-galeessaa gidduu jiru sadarkaa walitti dhukaasuurra gaheera.',\n",
       " 'Kanarra darbees Ministirri Muummee Abiy Ahimad raayyaan ittisa biyyaa tarkaanfii akka fudhatan ajajaniiru.',\n",
       " \"Eessarraa ka'anii asirraa ka'an garuu?\",\n",
       " '4 Sadaasa 2020\\nJireenyi siyaasaafi dhuunfaa kaadhimamotoota kanneenii waggoota 70 ol dabarsan keessatti maal akka fakkaatu yoo sonamu kana fakkaata.',\n",
       " '4 Sadaasa 2020\\nGaazexessituun Sudaan Zayinab Mohaammad Saalii, hidhi mormisiisaa Itoophiyaan ijaaraa jirtu Sudaaniif faayidaa fidu xalayaa BBC’f barreessiteen akkas jettee jirti.',\n",
       " '1 Sadaasa 2020\\nAs cuqaasuun kutaawwan haaraa torbaniin bahan argadhu, sadarkaan irra jirtu sin murteessu.',\n",
       " \"22 Guraandhala 2018\\nEjansii Immigireeshi,lammummaa fi Taateewwan Murteessoo fayyadamuun gama marsariitiin paaspoortii baasuufi haaressuun akka danda’amu dhaabbatichi beeksisee ture\\n28 Onkololeessa 2020\\nWeellisaa beekamaan Oromoo Haacaaluu Hundeessaa ALA Waxabajjii 29, 2020 (ALI Waxabajjii 22, 2012) galgala sa'a 3:30 irratti Magaalaa Finfinneetti rasaasaan rukutamee ajjeefame.\",\n",
       " \"Odeessi addatti qophaa'e kun waa'ee seenaa jireenyaa, maatiifi hojii artistii kanaati.\",\n",
       " '8 Fuulbaana 2020']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oro = pd.read_csv('2020-11-24-0-0-2.csv', names=[\"id\",\"url\",\"date\",\"title\",\"text\"] ,encoding=\"utf-8\")\n",
    "first_row = oro.loc[0, \"text\"]\n",
    "sent_tokenize(first_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7708b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oro['text'].apply(nltk.sent_tokenize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
